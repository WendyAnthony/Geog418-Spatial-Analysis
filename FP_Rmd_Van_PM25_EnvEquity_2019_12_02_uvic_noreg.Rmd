---
title: "Metro Vancouver PM2.5 & Environmental Equity"
author: "Wendy Anthony"
date: "11/26/2019"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---
# Introduction  
## Metro Vancouver environmental justice
Is there a relationship between PM2.5 air pollution and median income in Metro Vancouver?
# Set Working Directory
```{r Set_Working_Directory, include=TRUE, results="hide"}
#dir <- "/Users/geographydepartment/Documents/Geog418/FinalProject-Geog418/Working"  # homeComputer
 dir <- "/Users/wendyanthony/Documents/Geog418-AdvSpatialAnalysis/FinalProject/Working" # laptop
# dir <- "Z:/Geog418-FinalProject/Working" # labComputer
# dir <- "/Users/UVicCMC/Downloads/Data"  # CMCComputer
setwd(dir)
getwd()
```
# Install packages
Install all at once if not already installed.
```{r Install_Packages_at_once, include=TRUE, results="hide"}
# install.packages(c("sf", "plyr", "dplyr", "spdep", "GISTools", "raster", "rgdal", "spatstat", "sp", "tmap", "gstat", "maptools", "spgwr", "kable", "kableExtra"))
#install.packages("kable")
#install.packages("kableExtra")
#install.packages("bcmapsdata", repos = "https://bcgov.github.io/drat/")
#install.packages("moments")
```
# Load Libraries
Load Libraries needed to run the code. If these packages have not previously been installed, use function install.packages("") for each package.
``` {r Load_libraries, include=TRUE, results="hide"}
library("sf")
library("plyr")
library("dplyr")
library("spdep")
library("GISTools")
library("raster") # for making rasters for interpollated surfaces
library("rgdal")
library("spatstat")
library("sp")
library("spatstat")
library("tmap") # for creating themed choropleth maps
library("gstat")
library("maptools")
library("spgwr") # for geographic weighted regression
library("knitr")
library("kableExtra")
library("bcmapsdata") # for study area inset map
library("grid") # used to create inset map
library("moments") # used for skewness and kurtosis Descriptive Stats
```
# Data Preparation
## Dataset I: PM2.5 dataset
### Read in particulate matter dataset
```{r Read_in_PM25_particulate_matter_dataset}
## Dataset I. PM2.5 particulate matter dataset
pm25 <- read.csv("PM25.csv") #Read in PM2.5 data
```
**Info about pm25 dataset**
```{r Info_about_pm25_data_class}
class(pm25)
```
```{r Info_about_pm25_data_str}
str(pm25)
```
```{r Info_about_pm25_data_head}
head(pm25)
```
```{r Info_about_pm25_data_summary}
summary(pm25)
```
### Select only columns 1 and 2
``` {r Select_columns_1_and_2_pm25}
pm25 <- pm25[, 1:2]
```
### Change the column names
``` {r Change_column_names_pm25}
colnames(pm25) <- c("POSTALCODE", "PM25")
head(pm25)
```
**Create table pm25 head**
```{r kable_head_pm25}
# makes html table
kable(head(pm25))
write.csv(pm25, "pm25.csv", row.names = FALSE)
```
**Info about new columns pm25 pm25**
```{r Class_new_columns_pm25_pm25}
class(pm25$PM25)
```
**Info about new columns pm25 POSTALCODE**
```{r Class_new_columns_pm25_POSTALCODE}
class(pm25$POSTALCODE)
```
**Number of rows in pm25**
``` {r Number_of_rows_in_pm25}
nrow(pm25)
```
## Dataset II: postal code shapefile
``` {r Read_in_postal_code_shapefile_data}
## Dataset II. BC Postal Codes
postalcodes <- shapefile("./BC_PostalCodes/BC_Postal_Codes.shp")
```
**What is data type class of postalcodes data?**
```{r Class_of_postalcodes_data}
class(postalcodes)
```
**Display structure of postalcodes**
```{r String_structure_postalcodes}
str(postalcodes) 
```
**What is projection of postalcodes data?**
```{r Projection_of_postalcodes_data}
crs(postalcodes)
```
### Reproject postalcodes data to BC Albers, and rename variable to transformed 't'
```{r Transform_reproject_postalcodes_BC_Albers}
postalcodes.t <- spTransform(postalcodes, CRS("+init=epsg:3005"))
```
```{r Recheck_projection_postalcoades}
crs(postalcodes.t)
```
**Class of Postal Codes data**
``` {r Info_about_data_1}
class(postalcodes.t)
```
**Create table postalcodes.t head**
```{r kable_head_postalcode}
# makes html table
kable(head(postalcodes.t))
write.csv(postalcodes.t, "postalcodes.t.csv", row.names = FALSE)
```
**Class of postalcodes column POSTALCODE**
``` {r Class_postalcodes_POSTALCODE}
class(postalcodes.t$POSTALCODE)
```
## Dataset III. Census Income Data
``` {r Read_in_census_income_csv}
## Dataset III. Median Income
income <- read.csv("Income.csv")
```
**Info about income class data type**
```{r Class_income_data}
class(income)
head(income)
class(income$COL1)
class(income$COL0)
```
**Summary of income data**
```{r Summary_income_data}
summary(income)
```
### Select only ID and Income columns & rename
``` {r Select_only_ID_and_Income_columns}
colnames(income) <- c("DAUID", "Income") 
head(income)
```
**Create table income head**
```{r kable_head_income}
# makes html table
kable(head(income))
write.csv(income, "income.csv", row.names = FALSE)
```
## Dataset IV: Dissemination Tract Shapefile
### Read in dissemination tract shapefile
``` {r Read_in_dissemination_tract_shapefile}
## Dataset IV. Census tract polygons
census.tracts <- shapefile("./BC_DA/BC_DA.shp")
census.tracts
```
**Info about cenus.tracts**
```{r Info_census.tracts}
head(census.tracts)
class(census.tracts$DAUID) # [1] "character"
```
**Create table census.tracts head**
```{r kable_head_censustracts}
# makes html table
kable(head(census.tracts))
write.csv(census.tracts, "census.tracts.csv", row.names = FALSE)
```
**What is projection of censustracts data?**
```{r Projection_of_censustracts_data}
crs(census.tracts)
```
### Reproject censustracts data to BCAlbers, and rename variable to transformed 't'
```{r Reproject_censustracts_data_to_BCAlbers}
census.tracts.t <- spTransform(census.tracts, CRS("+init=epsg:3005"))
crs(census.tracts.t)
```
### Merge income and dissemination data, transfers projection with merge
``` {r Merge_income_and_census.tracts_dissemination_data}
income.tracts.t <- merge(census.tracts.t, income, by = "DAUID") 
income.tracts.t
```
**Info about merge income.tracts.t & census tracts**
```{r Info_about_merge_income.tracts.t_head}
head(income.tracts.t)
```
**Create table census.tracts head**
```{r kable_head_censustracts2}
# makes html table
kable(head(census.tracts))
write.csv(census.tracts, "census.tracts.1.csv", row.names = FALSE)
```
**Summary info about merge income.tracts.t & census tracts**
```{r Info_about_merge_income.tracts.t_summary}
summary(income.tracts.t)
```
**Determine the number of rows in the dataframe**
``` {r Number_rows_income.tracts_before_is.na}
nrow(income.tracts.t)
```
### Only include income columns not na
``` {r Include_income_not_na}
income.tracts.t <- income.tracts.t[!is.na(income.tracts.t$Income),]
```
**Determine the number of rows in the dataframe after is.na**
``` {r Number_rows_income.tracts.t_after_is.na}
nrow(income.tracts.t)
```
**Summary of income.tracts.t**
``` {r Summary_income.tracts.t}
summary(income.tracts.t)
```
**Info about income.tracts.t @data**
```{r Income.tracts.t_data}
income.tracts.t@data
```
### Create choropleth map of income
``` {r Create_choropleth_map_of_income}
map_MdInc.t <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "Income", 
              title = "Median Income", 
              style = "fisher", 
              palette = "viridis", n = 6,
              border.col = "grey", 
              border.alpha = 0.05) + 
  tm_compass(position = c("LEFT", "BOTTOM")) + 
  tm_scale_bar(width = 0.22, position = c("LEFT", "BOTTOM")) + 
  # add compass
  tm_layout(title = "Metro Vancouver Census Tracts Median Income \n2016", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .08, .03))
map_MdInc.t
```
**Create choropleth map png of Median Income and Income tracts**
``` {r Create_choropleth_map_png}
png("map_MdInc.t_income.tracts.t_fisher.png")  
map_MdInc.t
dev.off()
```
``` {r Find_projections}
crs(income.tracts.t)
crs(postalcodes.t)
```
### Select postal codes that fall within dissemination tracts
```{r Intersect_postalcodes_incometracts}
postalcodes.t <- intersect(postalcodes.t, income.tracts.t)
```
**Find projection of intersection of postalcodes & income.tracts**
``` {r Find_projections_intersection_postalcodes}
crs(postalcodes.t)
```
### See what the data looks like spatially
``` {r Plot_data_spatially}
plot(postalcodes.t) 
```
### See what the data looks like in tabular form
``` {r Data_Tabular}
head(postalcodes.t) 
```
**Create table postalcodes.t head**
```{r kable_head_postalcodes2}
# makes html table
kable(head(postalcodes.t))
write.csv(postalcodes.t, "postalcodes.t.csv", row.names = FALSE)
```
**Create postalcodes.t plot png**
``` {r Create_postalcodes.t_plot_png}
png("plot_postalcodes.t_incometracts_intersect.png")
plot(postalcodes.t)
dev.off()
```
```{r Pm25_summary}
# pm25
summary(pm25)
```
### Merge PM2.5 data with postal code data
``` {r Merge_PM2.5_data_with_postal_code_data}
pm25.spatial <- merge(postalcodes.t, pm25, by = "POSTALCODE")
```
**Info about pm25.spatial data**
``` {r Info_about_pm25.spatial_data}
nrow(pm25.spatial)  # 58320
ncol(pm25.spatial) # 29
head(pm25.spatial)
summary(pm25.spatial)   # NA's 450
```
```{r Info_pm25.spatial}
nrow(pm25.spatial)  # 58320
ncol(pm25.spatial) # 29
head(pm25.spatial)
class(pm25.spatial) # [1] "SpatialPointsDataFrame"
class(pm25.spatial$PM25) # [1] "factor"
```
```{r Summary_pm25_before_is.na}
summary(pm25.spatial)   # NA's 450 in PM25
```
### Remove na pm25.spatial
```{r Remove_na_pm25.spatial}
pm25.spatial <- pm25.spatial[!is.na(pm25.spatial$PM25),]  # removed all NA's
class(pm25.spatial$PM25) # [1] "factor"
```
```{r Summary_pm25_after_is.na}
summary(pm25.spatial)   # NA's 0 in PM25
```
**Create table pm25.spatial head**
```{r kable_head_pm25spatial}
# makes html table
kable(head(pm25.spatial))
write.csv(pm25.spatial, "pm25.spatial.csv", row.names = FALSE)
```
### Aggregate the PM2.5 values in each DA in order to have a single value per DA.
``` {r Aggregate_PM2.5_values_in_DA_for_single_value_per_DA}
pm25.aggregate <- aggregate((as.numeric(pm25.spatial$PM25)/10)~pm25.spatial$DAUID, FUN=max)
head(pm25.aggregate)
```
```{r Info_about_pm25.aggregate}
nrow(pm25.aggregate)  # 3355
head(pm25.aggregate)
summary(pm25.aggregate)
```
**Info_about_pm25.spatial$DAUID_data**
```{r Info_about_pm25.spatial}
class(pm25.spatial$PM25) # [1] "factor"
pm25.spatial$DAUID
summary(pm25.spatial$DAUID)
pm25.spatial$PM25
summary(pm25.spatial$PM25)  # NA's 0
is.na(pm25.spatial$PM25)
summary(pm25.spatial)
```
### Re-join aggregated data to the income.tracts.t layer.
Select only ID and Income columns & rename
``` {r Re-join_aggregated_data_to_the_income.tracts.t layer}
colnames(pm25.aggregate) <- c("DAUID", "PM25AGG") 
head(pm25.aggregate)
```
**Create table pm25.aggregate head**
```{r kable_head_pm25aggregatel}
# makes html table
kable(head(pm25.aggregate))
write.csv(pm25.aggregate, "pm25.aggregate.csv", row.names = FALSE)
```
```{r Info_pm25.aggregate$PM25AGG}
summary(pm25.aggregate$PM25AGG)
class(pm25.aggregate$PM25AGG) # [1] "numeric"
pm25.aggregate$PM25AGG
```
### Merge income and dissemination data
``` {r Merge_income.t_and_pm25_aggregate_dissemination_data}
income.pm25 <- merge(income.tracts.t, pm25.aggregate, by = "DAUID") 
income.pm25
summary(income.pm25)  # NA;s 8 in $PM25AGG
```
### Remove na income.pm25$PM25AGG
```{r Remove_na_income.pm25$PM25AGG}
income.pm25 <- income.pm25[!is.na(income.pm25$PM25AGG),] 
summary(income.pm25)  # no NA's
```
### Re-join aggregated data to the pm25.spatial points layer
``` {r Re-join_aggregated_data_to_pm25.spatial_points_layer}
pm25.points.aggregate <- merge(pm25.spatial, pm25.aggregate, by = "DAUID")
pm25.points.aggregate
```
**Info about data pm25.points.aggregate**
``` {r Info_about_data_pm25.points.aggregate}
class(pm25.points.aggregate) # [1] "SpatialPointsDataFrame"
head(pm25.points.aggregate)
summary(pm25.points.aggregate) # PM25 NA's 0  PM25AGG NA's 0
nrow(pm25.points.aggregate)   #58320
```
**Create table pm25.points.aggregate head**
```{r kable_head_pm25.pointsaggregate}
# makes html table
kable(head(pm25.points.aggregate))
write.csv(pm25.points.aggregate, "pm25.points.aggregate.csv", row.names = FALSE)
```
### Create a subsample of the datapoints provided in the PM2.5 dataset using the sample n=100
``` {r Create_subsample_of_datapoints_PM2.5_dataset_using_sample_n=100}
set.seed(100)
sampleSize=100
spSample <- pm25.points.aggregate[sample(1:length(pm25.points.aggregate), sampleSize),]
spSample
```
**Info about subset data spSample**
``` {r Info_about_subset_data_spSample}
head(spSample)
nrow(spSample)   # 100 > sample size
summary(spSample)  # no NA's
spSample@data
```
**Create table spSample head**
```{r kable_head_spSample}
# makes html table
kable(head(spSample))
write.csv(spSample, "spSample.csv", row.names = FALSE)
```
**Create sample plot**
```{r Plot_spSample}
plot(spSample)
```
**Create sample plot png**
```{r Create_sample_plot_png}
png("plot_spSample_100.png")
plot(spSample)
dev.off()
```
### Create a grid called grd to use in interpolation, where n is the total number of cells
``` {r Create_grid_to_use_in_interpolation_n_is_total_number_cells}
grd <- as.data.frame(spsample(spSample, "regular", n=5000))
names(grd)       <- c("X", "Y")
coordinates(grd) <- c("X", "Y")
gridded(grd)     <- TRUE  # Create SpatialPixel object
fullgrid(grd)    <- TRUE  # Create SpatialGrid object
proj4string(grd) <- proj4string(spSample)
grd
```
**Info about grd data**
``` {r Info_about_grd_data}
head(grd)
summary(grd)
```
```{r Grd_crs_class_summary_info}
crs(grd)
class(grd)
summary(grd)
```
### Create choropleth map with layer of sample=100 data points
``` {r Create_choropleth_map_with_layer_of_sample_100_data_points}
map_pm25_vit.data_medInc <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "Income", 
              title = "Median Income", 
              style = "fisher", 
              palette = "viridis", n = 6,
              border.col = "grey", 
              border.alpha = 0.05) +
  tm_shape(spSample) +
  # using minus sign before color -PuOr n=9, -RdBu n=9 reverses RdBu Brewer color scheme so Rd is hot & Bu is cold  
  #  tm_bubbles(size = "value", col = "red", scale = 1.3) + 
  tm_dots(col="PM25AGG", palette = "Reds", n=5, # n=9 gets finer detail? n = 7 or n=5  n=4, same with only 5 classes, even with no n=
          title="Sampled PM2.5 \n(ug/m^3)", size=0.08) + # , alpha = .5
  tm_legend(legend.outside=FALSE, position = c(0.01, 0.01)) + 
  ##?????? only showing 11 points /s/b 13 ??
  tm_layout(inner.margins = c(.15, .05, .15, .03), title = "Metro Vancouver 2016 Census Tracts\nMedian $ Income & Sampled PM2.5 Values", title.position = c("LEFT", "TOP")) + # 0.03, 0.92
  tm_scale_bar(position = c(0.4, 0.05)) +  # "LEFT", "BOTTOM"
  tm_compass(type= "4star", position=c("RIGHT", "TOP")) #"RIGHT", "TOP" 0.87, 0.82
map_pm25_vit.data_medInc
```
``` {r create_png_map_CT_MI}
png("map_pm25_vit.data_medIncome_smp100_1_dot.08.png")
map_pm25_vit.data_medInc
dev.off()
```
# Descriptive Stats
**Objects of interest: income.tracts.t, income.pm25, pm25.points.aggregate (before sample subset), spSample**  
**ensure no na values**
```{r}
summary(income.tracts.t)
summary(income.pm25)
summary(pm25.points.aggregate)
summary(spSample)
```
## mean
```{r Mean_calc}
mean.income.tracts.t.Income <- mean(income.tracts.t$Income)  # used by Moran's i
mean.income.tracts.t.Income # [1] 33868
mean.income.pm25.PM25AGG <- mean(income.pm25$PM25AGG)
mean.income.pm25.PM25AGG # [1] 2.13386

mean.spSample.Income <- mean(spSample$Income)
mean.spSample.Income # [1] 36021.82
mean.spSample.PM25AGG <- mean(spSample$PM25AGG)
mean.spSample.PM25AGG # [1] 1.996
```
## Standard Deviation
```{r SD_calc}
sd.income.tracts.t.Income <- sd(income.tracts.t$Income)
sd.income.tracts.t.Income # [1] 8835.894
sd.income.pm25.PM25AGG <- sd(income.pm25$PM25AGG)
sd.income.pm25.PM25AGG # [1] 1.509542

sd.spSample.Income <- sd(spSample$Income)
sd.spSample.Income # [1] 9416.431
sd.spSample.PM25AGG <- sd(spSample$PM25AGG)
sd.spSample.PM25AGG # [1] 1.491316
```
## Mode
**make frequency table of fire size variable and sort it in desending order and extract the first row (Most Frequent)**
```{r Mode_calc}
mode.income.tracts.t.Income <- as.numeric(names(sort(table(income.tracts.t$Income), decreasing = TRUE))[1])
mode.income.tracts.t.Income # [1] 34176
mode.income.pm25.PM25AGG <- as.numeric(names(sort(table(income.pm25$PM25AGG), decreasing = TRUE))[1])
mode.income.pm25.PM25AGG # [1] 0.1

mode.spSample.Income <- as.numeric(names(sort(table(spSample$Income), decreasing = TRUE))[1])
mode.income.tracts.t.Income # [1] 34176
mode.spSample.PM25AGG <- as.numeric(names(sort(table(spSample$PM25AGG), decreasing = TRUE))[1])
mode.spSample.PM25AGG # [1] 0.1
```
## Median
```{r Median_calc}
med.income.tracts.t.Income <- median(income.tracts.t$Income, na.rm = TRUE)
med.income.tracts.t.Income # [1] 33152
med.income.pm25.PM25AGG <- median(income.pm25$PM25AGG, na.rm = TRUE)
med.income.pm25.PM25AGG # [1] 2

med.spSample.Income <- median(spSample$Income, na.rm = TRUE)
med.spSample.Income # [1] 34752
med.spSample.PM25AGG <- median(spSample$PM25AGG, na.rm = TRUE)
med.spSample.PM25AGG # [1] 1.8
```
## Skewness   
**Needs package moments**
```{r Skewness_calc}
skew.income.tracts.t.Income <- skewness(income.tracts.t$Income, na.rm = TRUE)[1]
skew.income.tracts.t.Income # [1] 0.4087659
skew.income.pm25.PM25AGG <- skewness(income.pm25$PM25AGG, na.rm = TRUE)[1]
skew.income.pm25.PM25AGG # [1] 0.2479925

skew.spSample.Income <- skewness(spSample$Income, na.rm = TRUE)[1]
skew.spSample.Income # [1] 0.4296544
skew.spSample.PM25AGG <- skewness(spSample$PM25AGG, na.rm = TRUE)[1]
skew.spSample.PM25AGG # [1] 0.3529682
```
## Kurtosis 
**Needs package moments**
```{r Kurtosis_calc}
kurt.income.tracts.t.Income <- kurtosis(income.tracts.t$Income, na.rm = TRUE)[1]
kurt.income.tracts.t.Income # [1] 2.902638
kurt.income.pm25.PM25AGG <- kurtosis(income.pm25$PM25AGG, na.rm = TRUE)[1]
kurt.income.pm25.PM25AGG # [1] 2.044512

kurt.spSample.Income <- kurtosis(spSample$Income, na.rm = TRUE)[1]
kurt.spSample.Income # [1] 2.328493
kurt.spSample.PM25AGG <- kurtosis(spSample$PM25AGG, na.rm = TRUE)[1]
kurt.spSample.PM25AGG # [1] 2.05602
```
## CoVariance
```{r CoV_calc}
CoV.income.tracts.t.Income <- (sd.income.tracts.t.Income / mean.income.tracts.t.Income) * 100
CoV.income.tracts.t.Income # [1] 26.08921
CoV.income.pm25.PM25AGG <- (sd.income.pm25.PM25AGG / mean.income.pm25.PM25AGG) * 100
CoV.income.pm25.PM25AGG # [1] 70.7423

CoV.spSample.Income <- (sd.spSample.Income / mean.spSample.Income) * 100
CoV.spSample.Income # [1] 26.14091
CoV.spSample.PM25AGG <- (sd.spSample.PM25AGG / mean.spSample.PM25AGG) * 100
CoV.spSample.PM25AGG # [1] 74.71524
```
## Normal distribution test
```{r Normal_dist_calc}
norm.income.tracts.t.Income_PVAL <- shapiro.test(income.tracts.t$Income)$p.value
norm.income.tracts.t.Income_PVAL # [1] 7.991269e-20
norm.income.pm25.PM25AGG_PVAL <- shapiro.test(income.pm25$PM25AGG)$p.value
norm.income.pm25.PM25AGG_PVAL # [1] 6.341768e-34

norm.spSample.Income_PVAL <- shapiro.test(spSample$Income)$p.value
norm.spSample.Income_PVAL # [1] 0.005087551
norm.spSample.PM25AGG_PVAL <- shapiro.test(spSample$PM25AGG)$p.value
norm.spSample.PM25AGG_PVAL # [1] 7.730187e-05
```
## Create a table of descriptive stats 
### Create an object for the labels
```{r Label_object}
Samples <- c("Income (All)", "Income (Sample)", "PM2.5 (All)", "PM2.5 (Sample)") 
Samples
```
### Create an object for the means
```{r Mean_object}
Mean <- c(mean.income.tracts.t.Income, mean.spSample.Income, mean.income.pm25.PM25AGG, mean.spSample.PM25AGG) 
Mean = round(Mean, 3)
Mean
```
### Create an object for the standard deviations
```{r SD_object}
StandardDeviation <- c(sd.income.tracts.t.Income, sd.spSample.Income, sd.income.pm25.PM25AGG, sd.spSample.PM25AGG) 
StandardDeviation = round(StandardDeviation, 3)
StandardDeviation
```
### Create an object for the medians
```{r Median_object}
Median <- c(med.income.tracts.t.Income, med.spSample.Income, med.income.pm25.PM25AGG, med.spSample.PM25AGG) 
Median = round(Median, 3)
Median
```
### Create an object for the modes
```{r Mode_object}
Mode <- c(mode.income.tracts.t.Income, mode.spSample.Income, mode.income.pm25.PM25AGG, mode.spSample.PM25AGG) 
Mode = round(Mode, 3)
Mode
```
### Create an object for the skewness
```{r Skewness_object}
Skewness <- c(skew.income.tracts.t.Income, skew.spSample.Income, skew.income.pm25.PM25AGG, skew.spSample.PM25AGG) 
Skewness = round(Skewness, 3)
Skewness
```
### Create an object for the kurtosis
```{r Kurtosis_object}
Kurtosis <- c(kurt.income.tracts.t.Income, kurt.spSample.Income, kurt.income.pm25.PM25AGG, kurt.spSample.PM25AGG) 
Kurtosis = round(Kurtosis, 3)
Kurtosis
```
### Create an object for the CoV
```{r CoV_object}
CoefficientOfVariation <- c(CoV.income.tracts.t.Income, CoV.spSample.Income, CoV.income.pm25.PM25AGG, CoV.spSample.PM25AGG) 
CoefficientOfVariation = round(CoefficientOfVariation, 3)
CoefficientOfVariation
```
### Create an object for the normality PVALUE
```{r PVAL_object}
Normality <- c(norm.income.tracts.t.Income_PVAL, norm.spSample.Income_PVAL, norm.income.pm25.PM25AGG_PVAL, norm.spSample.PM25AGG_PVAL) 
Normality
```
### Add Stats data objects to data.frame ########
```{r Table_dataframe_DescStats}
data.for.table1.1 = data.frame(Samples, Mean, Median, Mode, StandardDeviation, CoefficientOfVariation, Skewness, Kurtosis, Normality)
data.for.table1 = data.frame(Samples, Mean, Median, Mode, StandardDeviation, CoefficientOfVariation)
data.for.table2 = data.frame(Samples, Skewness, Kurtosis, Normality)

data.for.table1.1
data.for.table1
data.for.table2
```
```{r Table_csv_write_DescStats}
write.csv(data.for.table1.1, "DescriptiveStats1.1.csv", row.names = FALSE)
write.csv(data.for.table1, "DescriptiveStats1.csv", row.names = FALSE)
write.csv(data.for.table2, "DescriptiveStats2.csv", row.names = FALSE)
```
# Spatial Autocorrelation
## Global Moran's I
### Defining Queen Neighbours
``` {r Defining_Queen_Neighbours}
vit.nb <- poly2nb(income.tracts.t)
vit.net <- nb2lines(vit.nb, coords=coordinates(income.tracts.t))
```
### Map Queen Neighbours (default weight scheme)
``` {r Map_Queen_Neighbours_default_weight_scheme}
# Map Queen Neighbours (default weight scheme).
map_vit.net <- tm_shape(income.tracts.t) + tm_borders(col='lightgrey') + 
  tm_shape(vit.net) + tm_lines(col='red') +
  # add scale bar - first value is TOP, second value is BOTTOM
  tm_scale_bar(width = 0.22, position = c("RIGHT", "BOTTOM")) + 
  # add compass
  tm_compass(position = c("RIGHT", "TOP")) + 
  tm_layout(title = "Metro Vancouver Census Tracts Median 2016 $ Income\nQueen Neighbours", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .08, .03))
# Create Neighbourhood map for Queen's weight.
map_vit.net
```
**Create png of Median Income vit.net Queen Neighbour**
``` {r Create_png_of_Median_Income_vit.net_Queen_Neighbour}
png("map_vit.net_Income_QueenN.png")  
map_vit.net
dev.off()
```
### Creating a Neighbourhood Weights Matrix
``` {r Creating_Neighbourhood_Weights_Matrix}
vit.lw <- nb2listw(vit.nb, zero.policy = TRUE, style = "W")
print.listw(vit.lw, zero.policy = TRUE)
```
### Mapping the Lagged Means  
**Calculate Lag Means**
``` {r Calculate_Lag_Means}
income.tracts.t$IncLagMeans = lag.listw(vit.lw, income.tracts.t$Income, zero.policy = TRUE)
```
**Mapping the Lagged Means**
Use "fisher" instead of "jenks" for larger data sets
``` {r Mapping_Lagged_Means}
map_LagMean <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "IncLagMeans", 
              title = "Median 2016 $ Income\nLagged Means", 
              style = "fisher", 
              palette = "viridis", n = 6,
              border.col = "grey", 
              border.alpha = 0.05) +
  # add scale bar - first value is TOP, second value is BOTTOM
  tm_compass(position = c("LEFT", "BOTTOM")) + 
  tm_scale_bar(width = 0.22, position = c("LEFT", "BOTTOM")) + 
  tm_layout(title = "Metro Vancouver Census Tracts \nMedian 2016 $ Income Lagged Means", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .13, .03))

######
## Use "fisher" instead of "jenks" for larger data sets

map_LagMean
```
**Create png of map LagMean Median Income**
``` {r Create_png_map_LagMean_Median_Income}
png("map_LagMean_vit_Income.png")  
map_LagMean
dev.off()
```
### Global Moran's I Test
``` {r Global_Morans_I_Test}
mi <- moran.test(income.tracts.t$Income, vit.lw, zero.policy = TRUE)
mi
```
**Moran Range**
``` {r Moran_Range}
moran.range <- function(lw) {
  wmat <- listw2mat(lw)
  return(range(eigen((wmat + t(wmat))/2)$values))
}
moran.range(vit.lw)
```
**Calculate Global Moran's z value**
``` {r Calculate_Global_Morans_z_value}
mI <- mi$estimate[[1]]
eI <- mi$estimate[[2]]
var <- mi$estimate[[3]]
z <- (mI - eI) / sqrt(var)
```
**Add Stats data objects to data.frame**
``` {r Add_Stats_data_objects_to_data.frame}
data.for.table1 = data.frame(mI, eI, var, z)
data.for.table1
```
**Create table data.for.table1 Moran's I**
```{r kable_head_datatable1}
# makes html table
kable(head(data.for.table1))
write.csv(data.for.table1, "data.for.table1.csv", row.names = FALSE)
```
**Write csv file with Global Moran's results for I, E, Var, Z, P**
``` {r Write_csv_file_with_Global_Morans_results}
write.csv(data.for.table1, "moransGlobal_vit_Income.csv", row.names = FALSE)
```
### Local Moran's i Test (Lisa Test)
``` {r Local_Morans_i_Lisa_Test}
lisa.test <- localmoran(income.tracts.t$Income, vit.lw)
```
**Create table lisa.test**
```{r kable_lisatest}
# makes html table
kable(head(lisa.test))
write.csv(lisa.test, "lisa.test.csv", row.names = FALSE)
```
**Lisa Test**
``` {r Lisa_Test}
income.tracts.t$Ii <- lisa.test[,1]
income.tracts.t$E.Ii<- lisa.test[,2]
income.tracts.t$Var.Ii<- lisa.test[,3]
income.tracts.t$Z.Ii<- lisa.test[,4]
income.tracts.t$P<- lisa.test[,5]
```
**If z value is less than 95% significance level, value is FALSE;**
``` {r z_Ii_values_test_value_FALSE_if_z_less_0.95_if_Ii_less_0_negative}
income.tracts.t$Z.Ho <- income.tracts.t$Z.Ii < 1.96
```
**If Ii value is less than 0 > negative**
```{r Ii_value_lessthan0_negative}
income.tracts.t$Ii.Neg <- income.tracts.t$Ii < 0
```
**P-value is one-tailed, need to multiply p-value x 2 to correspond to 95% 2 -tailed if P x 2>0.05 - higher chance of wrongly deciding significance**
``` {r P_onetail_value_test_multiply_by_2_for_twotail, include=TRUE, results="hide"}
income.tracts.t$Po <- (income.tracts.t$P * 2) > 0.05
income.tracts.t$Po
```
**Info about income.tracts Lisa test**
```{r Info_about_income.tracts_Lisa}
income.tracts.t
head(income.tracts.t)
income.tracts.t$Z.Ii
income.tracts.t$P
```
**make a data frome from the Lisa Test Data**
``` {r Make_data_frome_from_Lisa_Test_Data}
data.for.table2 = data.frame(income.tracts.t$DAUID, income.tracts.t$Income, income.tracts.t$IncLagMeans, income.tracts.t$Ii, income.tracts.t$E.Ii, income.tracts.t$Var.Ii, income.tracts.t$Z.Ii, income.tracts.t$P, income.tracts.t$Ii.Neg, income.tracts.t$Z.Ho, income.tracts.t$Po)
```
**Create table data.for.table1 Moran's i LISA**
```{r kable_head_datatable2}
# makes html table
kable(head(data.for.table2))
write.csv(data.for.table2, "Moransi.LISA.data.for.table2.csv", row.names = FALSE)
```
**Mapping the Local Moran's (LISA)**
``` {r Mapping_Local_Morans_LISA}
map_LISA <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "Ii", 
              title = "\nLocal Moran's i", 
              style = "fisher", 
              palette = "viridis", n = 6,
              border.col = "grey", 
              border.alpha = 0.05) + 
  tm_compass(position = c("LEFT", "BOTTOM")) + 
  tm_scale_bar(width = 0.22, position = c("LEFT", "BOTTOM")) +  
  tm_layout(title = "Metro Vancouver Census Tracts Median 2016 $ Income\nLocal Moran's i", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .13, .03))

map_LISA
```
**Create png of Map LISA Income**
``` {r Create_png_Map_LISA_Income}
png("map_LISA_vit_Income.png")  
map_LISA
dev.off()
```
**Mapping the Local Moran's (LISA) Z value**
``` {r Mapping_Local_Morans_LISA_Z}
# use manual breaks
# https://stackoverflow.com/questions/49423007/how-to-adjust-color-palette-with-customized-breaks-in-tmap
map_LISA_Z <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "Z.Ii", 
              title = "\nLocal Moran's i Z values",
              breaks = c(-Inf, -2.326, -1.96, 1.96, 2.326, Inf ),
              palette = "PuOr", n = 6,
              border.col = "grey", 
              border.alpha = 0.05) + 
  tm_compass(position = c("LEFT", "BOTTOM")) + 
  tm_scale_bar(width = 0.22, position = c("LEFT", "BOTTOM")) +  
  tm_layout(title = "Metro Vancouver Census Tracts Median 2016 $ Income\nLocal Moran's i Z values", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .13, .03))
map_LISA_Z
```
**Create png of Map LISA Income Z value**
``` {r Create_png_Map_LISA_Income_Z}
png("map_LISA_vit_Income_Z.png")  
map_LISA_Z
dev.off()
```
**Mapping the Local Moran's (LISA) P value**
``` {r Mapping_Local_Morans_LISA_P}
# use manual breaks
map_LISA_P <- tm_shape(income.tracts.t) + 
  tm_polygons(col = "P", 
              title = "\nLocal Moran's i P values",
              breaks = c(0, 0.001, 0.01, 0.05, Inf ),  # 95% p=0.05
              palette = "-BuPu", n = 5,
              border.col = "grey", 
              border.alpha = 0.05) + 
  tm_compass(position = c("LEFT", "BOTTOM")) + 
  tm_scale_bar(width = 0.22, position = c("LEFT", "BOTTOM")) +  
  tm_layout(title = "Metro Vancouver Census Tracts Median 2016 $ Income\nLocal Moran's i P values", title.position = c("LEFT", "TOP"), inner.margins = c(.08, .03, .13, .03))

map_LISA_P
```
**Create png of Map LISA Income P value**
``` {r Create_png_Map_LISA_Income_P}
png("map_LISA_vit_Income_P.png")  
map_LISA_P
dev.off()
```
**Local Moran's i Scatter Plot**
```{r Local_Morans_i_Scatter_Plot}
moran.plot(income.tracts.t$Income, vit.lw, zero.policy=NULL, spChk=NULL, labels=NULL, xlab="Median 2016 $ Income", 
           ylab="Spatially Lagged Mean Median 2016 $ Income", quiet=NULL, main ="Local Moran's i Plot for Metro Vancouver 2016 $ Income")
```
**Create png of Moran scatter plot**
``` {r Create_png_Moran_scatter_plot}
png("moran.plot_vit_Income.png")  
moran.plot(income.tracts.t$Income, vit.lw, zero.policy=NULL, spChk=NULL, labels=NULL, xlab="Median 2016 $ Income", 
           ylab="Spatially Lagged Mean Median 2016 $ Income", quiet=NULL, main ="Local Moran's i Plot for Metro Vancouver 2016 $ Income")
dev.off()
```
# Spatial Interpolation: Krigging Ordinary
## KO Variogram  
**Replace value with PM25AGG**
```{r Define_KO_formula}
f.0 <- as.formula(PM25AGG ~ 1) 
```
**Create KO variogram**  
**Plot PM2.5 KO Variogram Gaussian Model**
```{r Create_KO_variogram_Gaussian_model}
var.smpl <- variogram(f.0, spSample, cloud = FALSE) 
dat.fit.gau  <- fit.variogram(var.smpl, fit.ranges = FALSE, fit.sills = FALSE,
                          vgm(model="Gau"))
plot(var.smpl, dat.fit.gau, main = "PM2.5 Variogram Gaussian Model")
```
```{r}
summary(dat.fit.gau)
```
**Create png for Variogram Gaussian Model**
```{r Create_png_for_KO_Variogram_Gaussian_Model}
png("KO_PM25_Variogram_f0_Gau_bestfit.png")
plot(var.smpl, dat.fit.gau, main = "PM2.5 Variogram Gaussian Model")
dev.off()
```
**Plot PM2.5 KO Variogram Spherical Model**
```{r Create_KO_variogram_Spherical_model}
var.smpl <- variogram(f.0, spSample, cloud = FALSE) 
dat.fit.sph  <- fit.variogram(var.smpl, fit.ranges = FALSE, fit.sills = FALSE,
                          vgm(model="Sph"))
plot(var.smpl, dat.fit.sph, main = "PM2.5 Variogram Spherical Model")
```
```{r}
summary(dat.fit.sph)
```
**Create png for Variogram Spherical Model**
```{r Create_png_for_KO_Variogram_Sperical_Model}
png("KO_PM25_Variogram_f0_Sph_bestfit.png")
plot(var.smpl, dat.fit.sph, main = "PM2.5 Variogram Spherical Model")
dev.off()
```
**Plot PM2.5 KO Variogram Exponential Model**
```{r Create_KO_variogram_Exponential_model}
var.smpl <- variogram(f.0, spSample, cloud = FALSE) 
dat.fit  <- fit.variogram(var.smpl, fit.ranges = FALSE, fit.sills = FALSE,
                          vgm(model="Exp"))
```
**Plot PM2.5 KO Variogram Exponential Model**
```{r Plot_PM25_KO_Variogram_Exponential_Model}
plot(var.smpl, dat.fit, main = "PM2.5 Variogram Exponential Model")
```
```{r}
summary(dat.fit)
```
**Create png for Variogram Exponential Model**
```{r Create_png_for_KO_Variogram_Exponential_Model}
png("KO_PM25_Variogram_f0_Exp_bestfit.png")
plot(var.smpl, dat.fit, main = "PM2.5 Variogram Exponential Model")
dev.off()
```
## Krigging Interpolation
**Choose which best fit model to use for interpolation - Exponential**   
**Perform the krige interpolation (note the use of the variogram model created in the earlier step)**
```{r Perform_KO_krige_interpolation}
dat.krg <- krige( f.0, spSample, grd, dat.fit)
```
### Convert kriged surface to a raster object
```{r Convert_KO_kriged_surface_raster_object}
r <- raster(dat.krg)
```
**Info about kriged surface raster object**
```{r Info_about_KO_kriged_surface_raster_object}
r
class(r)
nrow(r)
summary(r) # no NAs
head(r)
```
### Plot the map of KO Predicted PM2.5 values
```{r Plot_map_KO_Predicted_PM25_values}
KO_PM25_predict_f0_Exp <- tm_shape(r) + 
  tm_raster(n=10, palette="Reds",  
            title="Predicted PM25 \n(ug/m^3)") +
  tm_shape(spSample) + tm_dots(size=0.2) +
  tm_legend(legend.outside=FALSE, position = c(0.01, 0.01)) + 
  tm_compass(position = c("RIGHT", "TOP")) + 
  tm_scale_bar(width = 0.22, position = c("RIGHT", "BOTTOM")) + 
  tm_layout(title = "Metro Vancouver Ordinary Kriging\nPM2.5 Predicted Values", title.position = c("LEFT", "TOP"), inner.margins = c(.15, .20, .13, .03))

KO_PM25_predict_f0_Exp
```
**Create png of predicted pm25**
```{r Create_png_KO_predicted_pm25}
png("KO_PM25_predict_f0_Exp.png")
KO_PM25_predict_f0_Exp
dev.off()
```
## KO Variance  
**Create_raster_KO_variance**
```{r Create_raster_KO_variance}
r <- raster(dat.krg, layer="var1.var")
```
### Create raster map of PM2.5 variance
```{r Create_raster_map_PM25_variance}
KO_PM25_variance_f0_Exp <- tm_shape(r) + 
  tm_raster(n=7, palette ="Reds",
            title="Variance PM25 \n(squared ug/m^3)") +
  tm_shape(spSample) + tm_dots(size=0.2) +
  tm_legend(legend.outside=FALSE, position = c(0.01, 0.01)) + 
  tm_compass(position = c("RIGHT", "TOP")) + 
  tm_scale_bar(width = 0.22, position = c("RIGHT", "BOTTOM")) + 
  tm_layout(title = "Metro Vancouver Ordinary Kriging \nPM2.5 Variance", title.position = c("LEFT", "TOP"), inner.margins = c(.15, .20, .13, .03))

r   <- sqrt(raster(dat.krg, layer="var1.var")) * 1.96
KO_PM25_variance_f0_Exp
```
```{r Summary_info_raster_map_PM25_variance}
summary(r)
nrow(r) #Determine the number of rows in the dataframe    # 49 rows
```
```{r Create_raster_map_PM25_variance_png}
png("KO_PM25_variance_f0_Exp.png")
KO_PM25_variance_f0_Exp
dev.off()
```
## KO Confidence Interval
```{r Create_raster_map_PM25_CI}
KO_PM25_CI_f0_Exp <- tm_shape(r) + 
  tm_raster(n=7, palette ="Reds",
            title="95% CI PM25 \n(ug/m^3)") + tm_shape(spSample) + tm_dots(size=0.2) +
  tm_legend(legend.outside=FALSE, position = c(0.01, 0.01)) + 
  tm_compass(position = c("RIGHT", "TOP")) + 
  tm_scale_bar(width = 0.22, position = c("RIGHT", "BOTTOM")) + 
  tm_layout(title = "Metro Vancouver Ordinary Kriging \nPM2.5 Confidence Intervals", title.position = c("LEFT", "TOP"), inner.margins = c(.15, .20, .13, .03))

KO_PM25_CI_f0_Exp
```
**Create raster map PM25 CI png**
```{r Create_raster_map_PM25_CI_png}
png("KO_PM25_CI_f0_Exp.png")
KO_PM25_CI_f0_Exp
dev.off()
```
### Perform_KO_krige_interpolation again for regression
```{r Perform_KO_krige_interpolation_2}
dat.krg <- krige( f.0, spSample, grd, dat.fit)
```
### Convert kriged surface to a raster objectagain for regression
```{r Convert_KO_kriged_surface_raster_object_2}
r <- raster(dat.krg)
```
## Combining Income and PM25
**Class of r raster**
```{r Class-of-r-raster}
class(r)
```
### Extract income.tracts and raster to create new object pm.income.poly
```{r Extract_incometracts_and_raster_to_create_new_object}
pm.income.poly <- extract(r, income.tracts.t, fun=mean, sp=TRUE)
pm.income.poly
```
**Summarize the result of extracting incometracts and raster**
```{r Summary_pm.incom.poly}
class(pm.income.poly) # [1] "SpatialPolygonsDataFrame"
head(pm.income.poly)
summary(pm.income.poly)  # layer has NA's 119
```
### new column was created 'layer'
```{r Summary_pm.incom.poly$layer}
class(pm.income.poly$layer) # [1] "numeric"
head(pm.income.poly$layer)
summary(pm.income.poly$layer) # NA's 119
```
**more info about pm.income.poly$layer**
```{r Info_about_pm.income.poly$layer}
str(pm.income.poly$layer)
pm.income.poly$layer
```
### NEED TO REMOVE NA'S
```{r Remove_nas_pm.income.poly$layer}
pm.income.poly <- pm.income.poly[!is.na(pm.income.poly$layer),] 
summary(pm.income.poly)  # NA's 0
```
**More info about pm.income.poly**
```{r More_info_about_pm.income.poly}
class(pm.income.poly) # [1] "SpatialPolygonsDataFrame"
head(pm.income.poly)
class(pm.income.poly$layer) # [1] "numeric"
names(pm.income.poly)  # names of columns
```
### NEED TO RENAME pm.income.poly$var1.pred > pm.income.poly$PM25Pred
```{r Rename_pm.income.poly$layer}
names(pm.income.poly)[names(pm.income.poly) == "layer"] <- "PM25.mean"
names(pm.income.poly)  # names of columns

summary(pm.income.poly)
```
```{r Head_columns_Income_PM25.mean}
head(pm.income.poly$Income)
head(pm.income.poly$PM25.mean)
```
# Extract R Code from Markdown Document
``` {r Extract_R_Code}
## Uncomment code to run after document knits successfully
 #library(knitr)
 #purl("FP_Rmd_Van_PM25_EnvEquity_2019_12_02_uvic.Rmd")
```
```{r session_info_packages_used}
#sessionInfo()
```

